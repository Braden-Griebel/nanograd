{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141dc0dc-62b3-4cf4-bf24-d6c33e347e5f",
   "metadata": {},
   "source": [
    "# Nanograd Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c44f3-176d-41f0-952b-706be7383fb5",
   "metadata": {},
   "source": [
    "Adaptded (mildly, just changing so it works with nanograd) from: https://github.com/karpathy/micrograd/blob/master/demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7422ef2-8be3-4387-9aa2-9ed128590635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d5b041-8577-4ff8-9c81-46f41b162a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanograd_bgriebel._core.engine import Value\n",
    "from nanograd_bgriebel._core.nn import Neuron, Layer, MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e177356-b638-46e9-9dca-3a553abee2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fda46db3340>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dataset for classification\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.1)\n",
    "\n",
    "y = y*2 - 1 # make y -1 or 1\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X[:,0], X[:,1], c=y, s=20, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeed3965-e241-4985-85ea-3976b6a37fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 337\n"
     ]
    }
   ],
   "source": [
    "# Create a multilayer perceptron\n",
    "model = MultiLayerPerceptron(2, [16,16,1]) # 2-layer neural network\n",
    "print(f\"Number of parameters: {len(model.get_parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6efcb61d-4140-47fd-9411-88f08bac7bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is: [Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "Score is [Value(data=396.278877, grad=0.000000)]\n",
      "Score in list is Value(data=396.278877, grad=0.000000)\n",
      "Input is: [Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "Score is [Value(data=505.751451, grad=0.000000)]\n",
      "Score in list is Value(data=505.751451, grad=0.000000)\n",
      "Input is: [Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "Score is [Value(data=39.905378, grad=0.000000)]\n",
      "Score in list is Value(data=39.905378, grad=0.000000)\n",
      "Input is: [Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "Score is [Value(data=663.405479, grad=0.000000)]\n",
      "Score in list is Value(data=663.405479, grad=0.000000)\n",
      "Input is: [Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Score is [Value(data=131.877321, grad=0.000000)]\n",
      "Score in list is Value(data=131.877321, grad=0.000000)\n",
      "Input is: [Value(data=0.623901, grad=0.000000), Value(data=-0.369177, grad=0.000000)]\n",
      "Score is [Value(data=137.276421, grad=0.000000)]\n",
      "Score in list is Value(data=137.276421, grad=0.000000)\n",
      "Input is: [Value(data=-0.125433, grad=0.000000), Value(data=0.906935, grad=0.000000)]\n",
      "Score is [Value(data=244.042731, grad=0.000000)]\n",
      "Score in list is Value(data=244.042731, grad=0.000000)\n",
      "Input is: [Value(data=0.209996, grad=0.000000), Value(data=1.066600, grad=0.000000)]\n",
      "Score is [Value(data=361.943041, grad=0.000000)]\n",
      "Score in list is Value(data=361.943041, grad=0.000000)\n",
      "Input is: [Value(data=0.662043, grad=0.000000), Value(data=0.876081, grad=0.000000)]\n",
      "Score is [Value(data=427.525743, grad=0.000000)]\n",
      "Score in list is Value(data=427.525743, grad=0.000000)\n",
      "Input is: [Value(data=1.986281, grad=0.000000), Value(data=0.267227, grad=0.000000)]\n",
      "Score is [Value(data=610.663992, grad=0.000000)]\n",
      "Score in list is Value(data=610.663992, grad=0.000000)\n",
      "Input is: [Value(data=-0.418061, grad=0.000000), Value(data=0.908797, grad=0.000000)]\n",
      "Score is [Value(data=181.549460, grad=0.000000)]\n",
      "Score in list is Value(data=181.549460, grad=0.000000)\n",
      "Input is: [Value(data=0.726086, grad=0.000000), Value(data=0.444818, grad=0.000000)]\n",
      "Score is [Value(data=336.577184, grad=0.000000)]\n",
      "Score in list is Value(data=336.577184, grad=0.000000)\n",
      "Input is: [Value(data=1.839880, grad=0.000000), Value(data=-0.176905, grad=0.000000)]\n",
      "Score is [Value(data=459.487786, grad=0.000000)]\n",
      "Score in list is Value(data=459.487786, grad=0.000000)\n",
      "Input is: [Value(data=1.998371, grad=0.000000), Value(data=0.139470, grad=0.000000)]\n",
      "Score is [Value(data=581.053303, grad=0.000000)]\n",
      "Score in list is Value(data=581.053303, grad=0.000000)\n",
      "Input is: [Value(data=0.599106, grad=0.000000), Value(data=0.976568, grad=0.000000)]\n",
      "Score is [Value(data=437.138443, grad=0.000000)]\n",
      "Score in list is Value(data=437.138443, grad=0.000000)\n",
      "Input is: [Value(data=-0.698100, grad=0.000000), Value(data=0.804663, grad=0.000000)]\n",
      "Score is [Value(data=114.307604, grad=0.000000)]\n",
      "Score in list is Value(data=114.307604, grad=0.000000)\n",
      "Input is: [Value(data=0.801801, grad=0.000000), Value(data=0.617867, grad=0.000000)]\n",
      "Score is [Value(data=397.201024, grad=0.000000)]\n",
      "Score in list is Value(data=397.201024, grad=0.000000)\n",
      "Input is: [Value(data=0.931948, grad=0.000000), Value(data=-0.317962, grad=0.000000)]\n",
      "Score is [Value(data=207.185470, grad=0.000000)]\n",
      "Score in list is Value(data=207.185470, grad=0.000000)\n",
      "Input is: [Value(data=0.944153, grad=0.000000), Value(data=-0.347926, grad=0.000000)]\n",
      "Score is [Value(data=203.491717, grad=0.000000)]\n",
      "Score in list is Value(data=203.491717, grad=0.000000)\n",
      "Input is: [Value(data=0.287004, grad=0.000000), Value(data=1.388442, grad=0.000000)]\n",
      "Score is [Value(data=462.680051, grad=0.000000)]\n",
      "Score in list is Value(data=462.680051, grad=0.000000)\n",
      "Input is: [Value(data=1.526756, grad=0.000000), Value(data=-0.362880, grad=0.000000)]\n",
      "Score is [Value(data=334.890445, grad=0.000000)]\n",
      "Score in list is Value(data=334.890445, grad=0.000000)\n",
      "Input is: [Value(data=-0.365979, grad=0.000000), Value(data=0.898402, grad=0.000000)]\n",
      "Score is [Value(data=190.220393, grad=0.000000)]\n",
      "Score in list is Value(data=190.220393, grad=0.000000)\n",
      "Input is: [Value(data=0.442625, grad=0.000000), Value(data=-0.089366, grad=0.000000)]\n",
      "Score is [Value(data=154.724343, grad=0.000000)]\n",
      "Score in list is Value(data=154.724343, grad=0.000000)\n",
      "Input is: [Value(data=0.303615, grad=0.000000), Value(data=0.895445, grad=0.000000)]\n",
      "Score is [Value(data=343.334465, grad=0.000000)]\n",
      "Score in list is Value(data=343.334465, grad=0.000000)\n",
      "Input is: [Value(data=-0.757905, grad=0.000000), Value(data=0.785406, grad=0.000000)]\n",
      "Score is [Value(data=103.484063, grad=0.000000)]\n",
      "Score in list is Value(data=103.484063, grad=0.000000)\n",
      "Input is: [Value(data=1.696162, grad=0.000000), Value(data=-0.230694, grad=0.000000)]\n",
      "Score is [Value(data=408.925909, grad=0.000000)]\n",
      "Score in list is Value(data=408.925909, grad=0.000000)\n",
      "Input is: [Value(data=0.175446, grad=0.000000), Value(data=-0.169856, grad=0.000000)]\n",
      "Score is [Value(data=100.679449, grad=0.000000)]\n",
      "Score in list is Value(data=100.679449, grad=0.000000)\n",
      "Input is: [Value(data=0.014467, grad=0.000000), Value(data=0.027205, grad=0.000000)]\n",
      "Score is [Value(data=105.297972, grad=0.000000)]\n",
      "Score in list is Value(data=105.297972, grad=0.000000)\n",
      "Input is: [Value(data=0.184558, grad=0.000000), Value(data=0.142345, grad=0.000000)]\n",
      "Score is [Value(data=149.793275, grad=0.000000)]\n",
      "Score in list is Value(data=149.793275, grad=0.000000)\n",
      "Input is: [Value(data=-0.912762, grad=0.000000), Value(data=0.459913, grad=0.000000)]\n",
      "Score is [Value(data=48.992606, grad=0.000000)]\n",
      "Score in list is Value(data=48.992606, grad=0.000000)\n",
      "Input is: [Value(data=-0.165053, grad=0.000000), Value(data=1.035774, grad=0.000000)]\n",
      "Score is [Value(data=264.533142, grad=0.000000)]\n",
      "Score in list is Value(data=264.533142, grad=0.000000)\n",
      "Input is: [Value(data=0.953378, grad=0.000000), Value(data=0.458986, grad=0.000000)]\n",
      "Score is [Value(data=395.331082, grad=0.000000)]\n",
      "Score in list is Value(data=395.331082, grad=0.000000)\n",
      "Input is: [Value(data=0.024177, grad=0.000000), Value(data=-0.118540, grad=0.000000)]\n",
      "Score is [Value(data=87.885435, grad=0.000000)]\n",
      "Score in list is Value(data=87.885435, grad=0.000000)\n",
      "Input is: [Value(data=-0.054088, grad=0.000000), Value(data=0.370447, grad=0.000000)]\n",
      "Score is [Value(data=147.937669, grad=0.000000)]\n",
      "Score in list is Value(data=147.937669, grad=0.000000)\n",
      "Input is: [Value(data=1.511685, grad=0.000000), Value(data=-0.352370, grad=0.000000)]\n",
      "Score is [Value(data=333.795796, grad=0.000000)]\n",
      "Score in list is Value(data=333.795796, grad=0.000000)\n",
      "Input is: [Value(data=-0.035296, grad=0.000000), Value(data=0.344327, grad=0.000000)]\n",
      "Score is [Value(data=146.647899, grad=0.000000)]\n",
      "Score in list is Value(data=146.647899, grad=0.000000)\n",
      "Input is: [Value(data=0.914758, grad=0.000000), Value(data=-0.412394, grad=0.000000)]\n",
      "Score is [Value(data=183.968041, grad=0.000000)]\n",
      "Score in list is Value(data=183.968041, grad=0.000000)\n",
      "Input is: [Value(data=1.242095, grad=0.000000), Value(data=-0.237379, grad=0.000000)]\n",
      "Score is [Value(data=296.691876, grad=0.000000)]\n",
      "Score in list is Value(data=296.691876, grad=0.000000)\n",
      "Input is: [Value(data=0.810409, grad=0.000000), Value(data=-0.555113, grad=0.000000)]\n",
      "Score is [Value(data=137.367907, grad=0.000000)]\n",
      "Score in list is Value(data=137.367907, grad=0.000000)\n",
      "Input is: [Value(data=0.602389, grad=0.000000), Value(data=-0.195820, grad=0.000000)]\n",
      "Score is [Value(data=164.959759, grad=0.000000)]\n",
      "Score in list is Value(data=164.959759, grad=0.000000)\n",
      "Input is: [Value(data=0.818799, grad=0.000000), Value(data=-0.401763, grad=0.000000)]\n",
      "Score is [Value(data=166.969501, grad=0.000000)]\n",
      "Score in list is Value(data=166.969501, grad=0.000000)\n",
      "Input is: [Value(data=0.214326, grad=0.000000), Value(data=0.811620, grad=0.000000)]\n",
      "Score is [Value(data=301.787181, grad=0.000000)]\n",
      "Score in list is Value(data=301.787181, grad=0.000000)\n",
      "Input is: [Value(data=1.270384, grad=0.000000), Value(data=-0.396882, grad=0.000000)]\n",
      "Score is [Value(data=265.200777, grad=0.000000)]\n",
      "Score in list is Value(data=265.200777, grad=0.000000)\n",
      "Input is: [Value(data=0.779211, grad=0.000000), Value(data=0.549288, grad=0.000000)]\n",
      "Score is [Value(data=374.400079, grad=0.000000)]\n",
      "Score in list is Value(data=374.400079, grad=0.000000)\n",
      "Input is: [Value(data=1.996109, grad=0.000000), Value(data=-0.055331, grad=0.000000)]\n",
      "Score is [Value(data=530.605267, grad=0.000000)]\n",
      "Score in list is Value(data=530.605267, grad=0.000000)\n",
      "Input is: [Value(data=0.939804, grad=0.000000), Value(data=-0.579890, grad=0.000000)]\n",
      "Score is [Value(data=156.002191, grad=0.000000)]\n",
      "Score in list is Value(data=156.002191, grad=0.000000)\n",
      "Input is: [Value(data=1.221601, grad=0.000000), Value(data=-0.485740, grad=0.000000)]\n",
      "Score is [Value(data=233.819163, grad=0.000000)]\n",
      "Score in list is Value(data=233.819163, grad=0.000000)\n",
      "Input is: [Value(data=0.665293, grad=0.000000), Value(data=0.776028, grad=0.000000)]\n",
      "Score is [Value(data=402.744040, grad=0.000000)]\n",
      "Score in list is Value(data=402.744040, grad=0.000000)\n",
      "Input is: [Value(data=-0.631946, grad=0.000000), Value(data=0.671198, grad=0.000000)]\n",
      "Score is [Value(data=104.988112, grad=0.000000)]\n",
      "Score in list is Value(data=104.988112, grad=0.000000)\n",
      "Input is: [Value(data=-0.370144, grad=0.000000), Value(data=0.942537, grad=0.000000)]\n",
      "Score is [Value(data=198.534046, grad=0.000000)]\n",
      "Score in list is Value(data=198.534046, grad=0.000000)\n",
      "Input is: [Value(data=-0.151293, grad=0.000000), Value(data=0.950733, grad=0.000000)]\n",
      "Score is [Value(data=248.060729, grad=0.000000)]\n",
      "Score in list is Value(data=248.060729, grad=0.000000)\n",
      "Input is: [Value(data=1.831978, grad=0.000000), Value(data=-0.008083, grad=0.000000)]\n",
      "Score is [Value(data=500.683195, grad=0.000000)]\n",
      "Score in list is Value(data=500.683195, grad=0.000000)\n",
      "Input is: [Value(data=0.959161, grad=0.000000), Value(data=0.054885, grad=0.000000)]\n",
      "Score is [Value(data=298.931369, grad=0.000000)]\n",
      "Score in list is Value(data=298.931369, grad=0.000000)\n",
      "Input is: [Value(data=-0.884492, grad=0.000000), Value(data=0.492619, grad=0.000000)]\n",
      "Score is [Value(data=54.541357, grad=0.000000)]\n",
      "Score in list is Value(data=54.541357, grad=0.000000)\n",
      "Input is: [Value(data=0.190673, grad=0.000000), Value(data=0.889378, grad=0.000000)]\n",
      "Score is [Value(data=314.772438, grad=0.000000)]\n",
      "Score in list is Value(data=314.772438, grad=0.000000)\n",
      "Input is: [Value(data=-0.803455, grad=0.000000), Value(data=0.368808, grad=0.000000)]\n",
      "Score is [Value(data=50.648990, grad=0.000000)]\n",
      "Score in list is Value(data=50.648990, grad=0.000000)\n",
      "Input is: [Value(data=1.497371, grad=0.000000), Value(data=-0.391382, grad=0.000000)]\n",
      "Score is [Value(data=320.997415, grad=0.000000)]\n",
      "Score in list is Value(data=320.997415, grad=0.000000)\n",
      "Input is: [Value(data=0.052715, grad=0.000000), Value(data=1.010549, grad=0.000000)]\n",
      "Score is [Value(data=310.743470, grad=0.000000)]\n",
      "Score in list is Value(data=310.743470, grad=0.000000)\n",
      "Input is: [Value(data=0.896137, grad=0.000000), Value(data=0.105594, grad=0.000000)]\n",
      "Score is [Value(data=295.975627, grad=0.000000)]\n",
      "Score in list is Value(data=295.975627, grad=0.000000)\n",
      "Input is: [Value(data=2.049158, grad=0.000000), Value(data=0.233812, grad=0.000000)]\n",
      "Score is [Value(data=618.206498, grad=0.000000)]\n",
      "Score in list is Value(data=618.206498, grad=0.000000)\n",
      "Input is: [Value(data=0.503940, grad=0.000000), Value(data=-0.340954, grad=0.000000)]\n",
      "Score is [Value(data=122.598340, grad=0.000000)]\n",
      "Score in list is Value(data=122.598340, grad=0.000000)\n",
      "Input is: [Value(data=0.244287, grad=0.000000), Value(data=1.018523, grad=0.000000)]\n",
      "Score is [Value(data=358.634668, grad=0.000000)]\n",
      "Score in list is Value(data=358.634668, grad=0.000000)\n",
      "Input is: [Value(data=0.908004, grad=0.000000), Value(data=0.460713, grad=0.000000)]\n",
      "Score is [Value(data=384.157355, grad=0.000000)]\n",
      "Score in list is Value(data=384.157355, grad=0.000000)\n",
      "Input is: [Value(data=0.544144, grad=0.000000), Value(data=-0.362927, grad=0.000000)]\n",
      "Score is [Value(data=125.515219, grad=0.000000)]\n",
      "Score in list is Value(data=125.515219, grad=0.000000)\n",
      "Input is: [Value(data=1.858998, grad=0.000000), Value(data=0.376194, grad=0.000000)]\n",
      "Score is [Value(data=605.975244, grad=0.000000)]\n",
      "Score in list is Value(data=605.975244, grad=0.000000)\n",
      "Input is: [Value(data=-0.159113, grad=0.000000), Value(data=0.831307, grad=0.000000)]\n",
      "Score is [Value(data=219.557731, grad=0.000000)]\n",
      "Score in list is Value(data=219.557731, grad=0.000000)\n",
      "Input is: [Value(data=-0.523605, grad=0.000000), Value(data=0.682850, grad=0.000000)]\n",
      "Score is [Value(data=121.999863, grad=0.000000)]\n",
      "Score in list is Value(data=121.999863, grad=0.000000)\n",
      "Input is: [Value(data=0.160544, grad=0.000000), Value(data=-0.002781, grad=0.000000)]\n",
      "Score is [Value(data=121.762668, grad=0.000000)]\n",
      "Score in list is Value(data=121.762668, grad=0.000000)\n",
      "Input is: [Value(data=-1.131076, grad=0.000000), Value(data=0.121296, grad=0.000000)]\n",
      "Score is [Value(data=18.534595, grad=0.000000)]\n",
      "Score in list is Value(data=18.534595, grad=0.000000)\n",
      "Input is: [Value(data=0.039880, grad=0.000000), Value(data=0.396541, grad=0.000000)]\n",
      "Score is [Value(data=170.691465, grad=0.000000)]\n",
      "Score in list is Value(data=170.691465, grad=0.000000)\n",
      "Input is: [Value(data=0.526645, grad=0.000000), Value(data=0.951324, grad=0.000000)]\n",
      "Score is [Value(data=412.125993, grad=0.000000)]\n",
      "Score in list is Value(data=412.125993, grad=0.000000)\n",
      "Input is: [Value(data=-0.609449, grad=0.000000), Value(data=0.822513, grad=0.000000)]\n",
      "Score is [Value(data=130.610839, grad=0.000000)]\n",
      "Score in list is Value(data=130.610839, grad=0.000000)\n",
      "Input is: [Value(data=0.065467, grad=0.000000), Value(data=0.243148, grad=0.000000)]\n",
      "Score is [Value(data=146.574636, grad=0.000000)]\n",
      "Score in list is Value(data=146.574636, grad=0.000000)\n",
      "Input is: [Value(data=0.967785, grad=0.000000), Value(data=0.215237, grad=0.000000)]\n",
      "Score is [Value(data=339.485651, grad=0.000000)]\n",
      "Score in list is Value(data=339.485651, grad=0.000000)\n",
      "Input is: [Value(data=0.719608, grad=0.000000), Value(data=0.793065, grad=0.000000)]\n",
      "Score is [Value(data=421.010269, grad=0.000000)]\n",
      "Score in list is Value(data=421.010269, grad=0.000000)\n",
      "Input is: [Value(data=0.270746, grad=0.000000), Value(data=-0.419485, grad=0.000000)]\n",
      "Score is [Value(data=80.925398, grad=0.000000)]\n",
      "Score in list is Value(data=80.925398, grad=0.000000)\n",
      "Input is: [Value(data=1.340812, grad=0.000000), Value(data=-0.230970, grad=0.000000)]\n",
      "Score is [Value(data=321.922299, grad=0.000000)]\n",
      "Score in list is Value(data=321.922299, grad=0.000000)\n",
      "Input is: [Value(data=1.106318, grad=0.000000), Value(data=0.136859, grad=0.000000)]\n",
      "Score is [Value(data=353.922587, grad=0.000000)]\n",
      "Score in list is Value(data=353.922587, grad=0.000000)\n",
      "Input is: [Value(data=1.221940, grad=0.000000), Value(data=-0.512805, grad=0.000000)]\n",
      "Score is [Value(data=227.832656, grad=0.000000)]\n",
      "Score in list is Value(data=227.832656, grad=0.000000)\n",
      "Input is: [Value(data=0.906122, grad=0.000000), Value(data=0.591725, grad=0.000000)]\n",
      "Score is [Value(data=417.214727, grad=0.000000)]\n",
      "Score in list is Value(data=417.214727, grad=0.000000)\n",
      "Input is: [Value(data=-0.310393, grad=0.000000), Value(data=1.065841, grad=0.000000)]\n",
      "Score is [Value(data=238.206536, grad=0.000000)]\n",
      "Score in list is Value(data=238.206536, grad=0.000000)\n",
      "Input is: [Value(data=-0.815160, grad=0.000000), Value(data=0.613759, grad=0.000000)]\n",
      "Score is [Value(data=74.268797, grad=0.000000)]\n",
      "Score in list is Value(data=74.268797, grad=0.000000)\n",
      "Input is: [Value(data=0.138429, grad=0.000000), Value(data=0.265516, grad=0.000000)]\n",
      "Score is [Value(data=164.456094, grad=0.000000)]\n",
      "Score in list is Value(data=164.456094, grad=0.000000)\n",
      "Input is: [Value(data=-0.859787, grad=0.000000), Value(data=-0.092258, grad=0.000000)]\n",
      "Score is [Value(data=20.337283, grad=0.000000)]\n",
      "Score in list is Value(data=20.337283, grad=0.000000)\n",
      "Input is: [Value(data=-0.999380, grad=0.000000), Value(data=0.066238, grad=0.000000)]\n",
      "Score is [Value(data=21.045259, grad=0.000000)]\n",
      "Score in list is Value(data=21.045259, grad=0.000000)\n",
      "Input is: [Value(data=0.925252, grad=0.000000), Value(data=0.150768, grad=0.000000)]\n",
      "Score is [Value(data=313.805020, grad=0.000000)]\n",
      "Score in list is Value(data=313.805020, grad=0.000000)\n",
      "Input is: [Value(data=0.779633, grad=0.000000), Value(data=0.768234, grad=0.000000)]\n",
      "Score is [Value(data=430.019723, grad=0.000000)]\n",
      "Score in list is Value(data=430.019723, grad=0.000000)\n",
      "Input is: [Value(data=-0.661991, grad=0.000000), Value(data=1.001899, grad=0.000000)]\n",
      "Score is [Value(data=152.160977, grad=0.000000)]\n",
      "Score in list is Value(data=152.160977, grad=0.000000)\n",
      "Input is: [Value(data=0.499896, grad=0.000000), Value(data=0.763805, grad=0.000000)]\n",
      "Score is [Value(data=358.848229, grad=0.000000)]\n",
      "Score in list is Value(data=358.848229, grad=0.000000)\n",
      "Input is: [Value(data=0.423686, grad=0.000000), Value(data=-0.142467, grad=0.000000)]\n",
      "Score is [Value(data=141.752904, grad=0.000000)]\n",
      "Score in list is Value(data=141.752904, grad=0.000000)\n",
      "Input is: [Value(data=-0.138544, grad=0.000000), Value(data=0.585683, grad=0.000000)]\n",
      "Score is [Value(data=172.749341, grad=0.000000)]\n",
      "Score in list is Value(data=172.749341, grad=0.000000)\n",
      "Input is: [Value(data=-0.911407, grad=0.000000), Value(data=0.138105, grad=0.000000)]\n",
      "Score is [Value(data=28.078257, grad=0.000000)]\n",
      "Score in list is Value(data=28.078257, grad=0.000000)\n",
      "Input is: [Value(data=1.864342, grad=0.000000), Value(data=-0.194818, grad=0.000000)]\n",
      "Score is [Value(data=461.164317, grad=0.000000)]\n",
      "Score in list is Value(data=461.164317, grad=0.000000)\n",
      "Input is: [Value(data=-0.874569, grad=0.000000), Value(data=0.475178, grad=0.000000)]\n",
      "Score is [Value(data=53.857269, grad=0.000000)]\n",
      "Score in list is Value(data=53.857269, grad=0.000000)\n",
      "Input is: [Value(data=0.453543, grad=0.000000), Value(data=-0.362497, grad=0.000000)]\n",
      "Score is [Value(data=112.073099, grad=0.000000)]\n",
      "Score in list is Value(data=112.073099, grad=0.000000)\n",
      "Input is: [Value(data=1.725202, grad=0.000000), Value(data=-0.285713, grad=0.000000)]\n",
      "Score is [Value(data=402.275210, grad=0.000000)]\n",
      "Score in list is Value(data=402.275210, grad=0.000000)\n",
      "Input is: [Value(data=0.151539, grad=0.000000), Value(data=-0.136246, grad=0.000000)]\n",
      "Score is [Value(data=101.921454, grad=0.000000)]\n",
      "Score in list is Value(data=101.921454, grad=0.000000)\n",
      "Input is: [Value(data=-0.813107, grad=0.000000), Value(data=0.363405, grad=0.000000)]\n",
      "Score is [Value(data=49.278958, grad=0.000000)]\n",
      "Score in list is Value(data=49.278958, grad=0.000000)\n",
      "Input is: [Value(data=1.728491, grad=0.000000), Value(data=-0.078335, grad=0.000000)]\n",
      "Score is [Value(data=456.205828, grad=0.000000)]\n",
      "Score in list is Value(data=456.205828, grad=0.000000)\n",
      "Input is: [Value(data=1.848914, grad=0.000000), Value(data=0.386789, grad=0.000000)]\n",
      "Score is [Value(data=606.105753, grad=0.000000)]\n",
      "Score in list is Value(data=606.105753, grad=0.000000)\n",
      "[Value(data=606.105753, grad=0.000000)]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for xrow in X:\n",
    "    input_ = [Value(xrow[0]), Value(xrow[1])]\n",
    "    print(f\"Input is: {input_}\")\n",
    "    scores = []\n",
    "    score = model(input_)\n",
    "    print(f\"Score is {score}\")\n",
    "    scores += score\n",
    "    print(f\"Score in list is {scores[idx]}\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "850e5565-039a-4be2-a040-3cd38ce8af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in scores:\n",
    "    score.backwards()\n",
    "\n",
    "for p in model.get_parameters():\n",
    "    p.data -= -1e-4 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d61a6511-f8bd-4d4f-8bd1-a2dadac8dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.938065, grad=0.000000)]\n",
      "[Value(data=-0.938065, grad=0.000000)]\n",
      "[Value(data=-0.938065, grad=0.000000)]\n",
      "[Value(data=-0.938065, grad=0.000000)]\n",
      "[Value(data=-0.938065, grad=0.000000)]\n",
      "Value(data=1.154373, grad=0.000000) 0.5\n"
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "def loss(batch_size=None):\n",
    "    \n",
    "    # inline DataLoader :)\n",
    "    if batch_size is None:\n",
    "        Xb, yb = X, y\n",
    "    else:\n",
    "        ri = np.random.permutation(X.shape[0])[:batch_size]\n",
    "        Xb, yb = X[ri], y[ri]\n",
    "    inputs = [list(map(Value, xrow)) for xrow in Xb]\n",
    "    print(\"Inputs:\")\n",
    "    for i in range(5):\n",
    "        print(inputs[i])\n",
    "    \n",
    "    # forward the model to get scores\n",
    "    scores = []\n",
    "    for input_ in inputs:\n",
    "        scores.append(model(input_))\n",
    "    print(\"Scores:\")\n",
    "    for i in range(5):\n",
    "        print(scores[i])\n",
    "    #scores = list(map(model, inputs))\n",
    "    # print(inputs[0])\n",
    "    # print(model(inputs[0]))\n",
    "    \n",
    "    #print(scores)\n",
    "    \n",
    "    # svm \"max-margin\" loss\n",
    "    # for yi, scorei in zip(yb, scores):\n",
    "    #     print(yi)\n",
    "    #     print(scorei)\n",
    "    losses = [(1 + -yi*scorei[0]).relu() for yi, scorei in zip(yb, scores)]\n",
    "    data_loss = sum(losses) * (1.0 / len(losses))\n",
    "    # L2 regularization\n",
    "    alpha = 1e-4\n",
    "    reg_loss = alpha * sum((p*p for p in model.get_parameters()))\n",
    "    total_loss = data_loss + reg_loss\n",
    "    \n",
    "    # also get accuracy\n",
    "    accuracy = [(yi > 0) == (scorei[0].data > 0) for yi, scorei in zip(yb, scores)]\n",
    "    return total_loss, sum(accuracy) / len(accuracy)\n",
    "\n",
    "total_loss, acc = loss()\n",
    "print(total_loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "510bd0ba-12f6-41b5-9aeb-a715551d04ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.938065, grad=0.000000)]\n",
      "[Value(data=-0.938065, grad=0.000000)]\n",
      "[Value(data=-0.938065, grad=0.000000)]\n",
      "[Value(data=-0.938065, grad=0.000000)]\n",
      "[Value(data=-0.938065, grad=0.000000)]\n",
      "step 0 loss 1.154372816437949, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.937878, grad=0.000000)]\n",
      "[Value(data=-0.937878, grad=0.000000)]\n",
      "[Value(data=-0.937878, grad=0.000000)]\n",
      "[Value(data=-0.937878, grad=0.000000)]\n",
      "[Value(data=-0.937878, grad=0.000000)]\n",
      "step 1 loss 1.1543110734862854, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.937692, grad=0.000000)]\n",
      "[Value(data=-0.937692, grad=0.000000)]\n",
      "[Value(data=-0.937692, grad=0.000000)]\n",
      "[Value(data=-0.937692, grad=0.000000)]\n",
      "[Value(data=-0.937692, grad=0.000000)]\n",
      "step 2 loss 1.1542499106385946, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.937508, grad=0.000000)]\n",
      "[Value(data=-0.937508, grad=0.000000)]\n",
      "[Value(data=-0.937508, grad=0.000000)]\n",
      "[Value(data=-0.937508, grad=0.000000)]\n",
      "[Value(data=-0.937508, grad=0.000000)]\n",
      "step 3 loss 1.1541893272235717, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.937325, grad=0.000000)]\n",
      "[Value(data=-0.937325, grad=0.000000)]\n",
      "[Value(data=-0.937325, grad=0.000000)]\n",
      "[Value(data=-0.937325, grad=0.000000)]\n",
      "[Value(data=-0.937325, grad=0.000000)]\n",
      "step 4 loss 1.1541293225764364, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.937144, grad=0.000000)]\n",
      "[Value(data=-0.937144, grad=0.000000)]\n",
      "[Value(data=-0.937144, grad=0.000000)]\n",
      "[Value(data=-0.937144, grad=0.000000)]\n",
      "[Value(data=-0.937144, grad=0.000000)]\n",
      "step 5 loss 1.1540698960389213, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.936965, grad=0.000000)]\n",
      "[Value(data=-0.936965, grad=0.000000)]\n",
      "[Value(data=-0.936965, grad=0.000000)]\n",
      "[Value(data=-0.936965, grad=0.000000)]\n",
      "[Value(data=-0.936965, grad=0.000000)]\n",
      "step 6 loss 1.1540110469592564, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.936788, grad=0.000000)]\n",
      "[Value(data=-0.936788, grad=0.000000)]\n",
      "[Value(data=-0.936788, grad=0.000000)]\n",
      "[Value(data=-0.936788, grad=0.000000)]\n",
      "[Value(data=-0.936788, grad=0.000000)]\n",
      "step 7 loss 1.1539527746921672, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.936613, grad=0.000000)]\n",
      "[Value(data=-0.936613, grad=0.000000)]\n",
      "[Value(data=-0.936613, grad=0.000000)]\n",
      "[Value(data=-0.936613, grad=0.000000)]\n",
      "[Value(data=-0.936613, grad=0.000000)]\n",
      "step 8 loss 1.1538950785988427, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.936439, grad=0.000000)]\n",
      "[Value(data=-0.936439, grad=0.000000)]\n",
      "[Value(data=-0.936439, grad=0.000000)]\n",
      "[Value(data=-0.936439, grad=0.000000)]\n",
      "[Value(data=-0.936439, grad=0.000000)]\n",
      "step 9 loss 1.1538379580469464, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.936267, grad=0.000000)]\n",
      "[Value(data=-0.936267, grad=0.000000)]\n",
      "[Value(data=-0.936267, grad=0.000000)]\n",
      "[Value(data=-0.936267, grad=0.000000)]\n",
      "[Value(data=-0.936267, grad=0.000000)]\n",
      "step 10 loss 1.1537814124105898, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.936096, grad=0.000000)]\n",
      "[Value(data=-0.936096, grad=0.000000)]\n",
      "[Value(data=-0.936096, grad=0.000000)]\n",
      "[Value(data=-0.936096, grad=0.000000)]\n",
      "[Value(data=-0.936096, grad=0.000000)]\n",
      "step 11 loss 1.1537254410703277, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.935928, grad=0.000000)]\n",
      "[Value(data=-0.935928, grad=0.000000)]\n",
      "[Value(data=-0.935928, grad=0.000000)]\n",
      "[Value(data=-0.935928, grad=0.000000)]\n",
      "[Value(data=-0.935928, grad=0.000000)]\n",
      "step 12 loss 1.153670043413145, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.935761, grad=0.000000)]\n",
      "[Value(data=-0.935761, grad=0.000000)]\n",
      "[Value(data=-0.935761, grad=0.000000)]\n",
      "[Value(data=-0.935761, grad=0.000000)]\n",
      "[Value(data=-0.935761, grad=0.000000)]\n",
      "step 13 loss 1.1536152188324438, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.935595, grad=0.000000)]\n",
      "[Value(data=-0.935595, grad=0.000000)]\n",
      "[Value(data=-0.935595, grad=0.000000)]\n",
      "[Value(data=-0.935595, grad=0.000000)]\n",
      "[Value(data=-0.935595, grad=0.000000)]\n",
      "step 14 loss 1.1535609667280364, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.935432, grad=0.000000)]\n",
      "[Value(data=-0.935432, grad=0.000000)]\n",
      "[Value(data=-0.935432, grad=0.000000)]\n",
      "[Value(data=-0.935432, grad=0.000000)]\n",
      "[Value(data=-0.935432, grad=0.000000)]\n",
      "step 15 loss 1.1535072865061293, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.935270, grad=0.000000)]\n",
      "[Value(data=-0.935270, grad=0.000000)]\n",
      "[Value(data=-0.935270, grad=0.000000)]\n",
      "[Value(data=-0.935270, grad=0.000000)]\n",
      "[Value(data=-0.935270, grad=0.000000)]\n",
      "step 16 loss 1.153454177579318, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.935110, grad=0.000000)]\n",
      "[Value(data=-0.935110, grad=0.000000)]\n",
      "[Value(data=-0.935110, grad=0.000000)]\n",
      "[Value(data=-0.935110, grad=0.000000)]\n",
      "[Value(data=-0.935110, grad=0.000000)]\n",
      "step 17 loss 1.1534016393665705, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.934951, grad=0.000000)]\n",
      "[Value(data=-0.934951, grad=0.000000)]\n",
      "[Value(data=-0.934951, grad=0.000000)]\n",
      "[Value(data=-0.934951, grad=0.000000)]\n",
      "[Value(data=-0.934951, grad=0.000000)]\n",
      "step 18 loss 1.1533496712932219, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.934795, grad=0.000000)]\n",
      "[Value(data=-0.934795, grad=0.000000)]\n",
      "[Value(data=-0.934795, grad=0.000000)]\n",
      "[Value(data=-0.934795, grad=0.000000)]\n",
      "[Value(data=-0.934795, grad=0.000000)]\n",
      "step 19 loss 1.1532982727909598, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.934640, grad=0.000000)]\n",
      "[Value(data=-0.934640, grad=0.000000)]\n",
      "[Value(data=-0.934640, grad=0.000000)]\n",
      "[Value(data=-0.934640, grad=0.000000)]\n",
      "[Value(data=-0.934640, grad=0.000000)]\n",
      "step 20 loss 1.153247443297817, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.934487, grad=0.000000)]\n",
      "[Value(data=-0.934487, grad=0.000000)]\n",
      "[Value(data=-0.934487, grad=0.000000)]\n",
      "[Value(data=-0.934487, grad=0.000000)]\n",
      "[Value(data=-0.934487, grad=0.000000)]\n",
      "step 21 loss 1.1531971822581584, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.934335, grad=0.000000)]\n",
      "[Value(data=-0.934335, grad=0.000000)]\n",
      "[Value(data=-0.934335, grad=0.000000)]\n",
      "[Value(data=-0.934335, grad=0.000000)]\n",
      "[Value(data=-0.934335, grad=0.000000)]\n",
      "step 22 loss 1.1531474891226736, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.934185, grad=0.000000)]\n",
      "[Value(data=-0.934185, grad=0.000000)]\n",
      "[Value(data=-0.934185, grad=0.000000)]\n",
      "[Value(data=-0.934185, grad=0.000000)]\n",
      "[Value(data=-0.934185, grad=0.000000)]\n",
      "step 23 loss 1.1530983633483665, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.934037, grad=0.000000)]\n",
      "[Value(data=-0.934037, grad=0.000000)]\n",
      "[Value(data=-0.934037, grad=0.000000)]\n",
      "[Value(data=-0.934037, grad=0.000000)]\n",
      "[Value(data=-0.934037, grad=0.000000)]\n",
      "step 24 loss 1.1530498043985427, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.933890, grad=0.000000)]\n",
      "[Value(data=-0.933890, grad=0.000000)]\n",
      "[Value(data=-0.933890, grad=0.000000)]\n",
      "[Value(data=-0.933890, grad=0.000000)]\n",
      "[Value(data=-0.933890, grad=0.000000)]\n",
      "step 25 loss 1.1530018117428025, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.933746, grad=0.000000)]\n",
      "[Value(data=-0.933746, grad=0.000000)]\n",
      "[Value(data=-0.933746, grad=0.000000)]\n",
      "[Value(data=-0.933746, grad=0.000000)]\n",
      "[Value(data=-0.933746, grad=0.000000)]\n",
      "step 26 loss 1.1529543848570305, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.933603, grad=0.000000)]\n",
      "[Value(data=-0.933603, grad=0.000000)]\n",
      "[Value(data=-0.933603, grad=0.000000)]\n",
      "[Value(data=-0.933603, grad=0.000000)]\n",
      "[Value(data=-0.933603, grad=0.000000)]\n",
      "step 27 loss 1.1529075232233865, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.933461, grad=0.000000)]\n",
      "[Value(data=-0.933461, grad=0.000000)]\n",
      "[Value(data=-0.933461, grad=0.000000)]\n",
      "[Value(data=-0.933461, grad=0.000000)]\n",
      "[Value(data=-0.933461, grad=0.000000)]\n",
      "step 28 loss 1.1528612263302949, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.933322, grad=0.000000)]\n",
      "[Value(data=-0.933322, grad=0.000000)]\n",
      "[Value(data=-0.933322, grad=0.000000)]\n",
      "[Value(data=-0.933322, grad=0.000000)]\n",
      "[Value(data=-0.933322, grad=0.000000)]\n",
      "step 29 loss 1.1528154936724355, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.933184, grad=0.000000)]\n",
      "[Value(data=-0.933184, grad=0.000000)]\n",
      "[Value(data=-0.933184, grad=0.000000)]\n",
      "[Value(data=-0.933184, grad=0.000000)]\n",
      "[Value(data=-0.933184, grad=0.000000)]\n",
      "step 30 loss 1.1527703247507362, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.933047, grad=0.000000)]\n",
      "[Value(data=-0.933047, grad=0.000000)]\n",
      "[Value(data=-0.933047, grad=0.000000)]\n",
      "[Value(data=-0.933047, grad=0.000000)]\n",
      "[Value(data=-0.933047, grad=0.000000)]\n",
      "step 31 loss 1.1527257190723605, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.932913, grad=0.000000)]\n",
      "[Value(data=-0.932913, grad=0.000000)]\n",
      "[Value(data=-0.932913, grad=0.000000)]\n",
      "[Value(data=-0.932913, grad=0.000000)]\n",
      "[Value(data=-0.932913, grad=0.000000)]\n",
      "step 32 loss 1.1526816761507042, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.932780, grad=0.000000)]\n",
      "[Value(data=-0.932780, grad=0.000000)]\n",
      "[Value(data=-0.932780, grad=0.000000)]\n",
      "[Value(data=-0.932780, grad=0.000000)]\n",
      "[Value(data=-0.932780, grad=0.000000)]\n",
      "step 33 loss 1.1526381955053784, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.932649, grad=0.000000)]\n",
      "[Value(data=-0.932649, grad=0.000000)]\n",
      "[Value(data=-0.932649, grad=0.000000)]\n",
      "[Value(data=-0.932649, grad=0.000000)]\n",
      "[Value(data=-0.932649, grad=0.000000)]\n",
      "step 34 loss 1.1525952766622098, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.932519, grad=0.000000)]\n",
      "[Value(data=-0.932519, grad=0.000000)]\n",
      "[Value(data=-0.932519, grad=0.000000)]\n",
      "[Value(data=-0.932519, grad=0.000000)]\n",
      "[Value(data=-0.932519, grad=0.000000)]\n",
      "step 35 loss 1.1525529191532229, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.932392, grad=0.000000)]\n",
      "[Value(data=-0.932392, grad=0.000000)]\n",
      "[Value(data=-0.932392, grad=0.000000)]\n",
      "[Value(data=-0.932392, grad=0.000000)]\n",
      "[Value(data=-0.932392, grad=0.000000)]\n",
      "step 36 loss 1.152511122516641, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.932266, grad=0.000000)]\n",
      "[Value(data=-0.932266, grad=0.000000)]\n",
      "[Value(data=-0.932266, grad=0.000000)]\n",
      "[Value(data=-0.932266, grad=0.000000)]\n",
      "[Value(data=-0.932266, grad=0.000000)]\n",
      "step 37 loss 1.1524698862968692, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.932141, grad=0.000000)]\n",
      "[Value(data=-0.932141, grad=0.000000)]\n",
      "[Value(data=-0.932141, grad=0.000000)]\n",
      "[Value(data=-0.932141, grad=0.000000)]\n",
      "[Value(data=-0.932141, grad=0.000000)]\n",
      "step 38 loss 1.152429210044492, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.932019, grad=0.000000)]\n",
      "[Value(data=-0.932019, grad=0.000000)]\n",
      "[Value(data=-0.932019, grad=0.000000)]\n",
      "[Value(data=-0.932019, grad=0.000000)]\n",
      "[Value(data=-0.932019, grad=0.000000)]\n",
      "step 39 loss 1.1523890933162626, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.931898, grad=0.000000)]\n",
      "[Value(data=-0.931898, grad=0.000000)]\n",
      "[Value(data=-0.931898, grad=0.000000)]\n",
      "[Value(data=-0.931898, grad=0.000000)]\n",
      "[Value(data=-0.931898, grad=0.000000)]\n",
      "step 40 loss 1.1523495356750957, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.931778, grad=0.000000)]\n",
      "[Value(data=-0.931778, grad=0.000000)]\n",
      "[Value(data=-0.931778, grad=0.000000)]\n",
      "[Value(data=-0.931778, grad=0.000000)]\n",
      "[Value(data=-0.931778, grad=0.000000)]\n",
      "step 41 loss 1.1523105366900572, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.931661, grad=0.000000)]\n",
      "[Value(data=-0.931661, grad=0.000000)]\n",
      "[Value(data=-0.931661, grad=0.000000)]\n",
      "[Value(data=-0.931661, grad=0.000000)]\n",
      "[Value(data=-0.931661, grad=0.000000)]\n",
      "step 42 loss 1.152272095936362, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.931545, grad=0.000000)]\n",
      "[Value(data=-0.931545, grad=0.000000)]\n",
      "[Value(data=-0.931545, grad=0.000000)]\n",
      "[Value(data=-0.931545, grad=0.000000)]\n",
      "[Value(data=-0.931545, grad=0.000000)]\n",
      "step 43 loss 1.152234212995358, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.931431, grad=0.000000)]\n",
      "[Value(data=-0.931431, grad=0.000000)]\n",
      "[Value(data=-0.931431, grad=0.000000)]\n",
      "[Value(data=-0.931431, grad=0.000000)]\n",
      "[Value(data=-0.931431, grad=0.000000)]\n",
      "step 44 loss 1.1521968874545276, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.931318, grad=0.000000)]\n",
      "[Value(data=-0.931318, grad=0.000000)]\n",
      "[Value(data=-0.931318, grad=0.000000)]\n",
      "[Value(data=-0.931318, grad=0.000000)]\n",
      "[Value(data=-0.931318, grad=0.000000)]\n",
      "step 45 loss 1.152160118907473, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.931207, grad=0.000000)]\n",
      "[Value(data=-0.931207, grad=0.000000)]\n",
      "[Value(data=-0.931207, grad=0.000000)]\n",
      "[Value(data=-0.931207, grad=0.000000)]\n",
      "[Value(data=-0.931207, grad=0.000000)]\n",
      "step 46 loss 1.1521239069539124, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.931098, grad=0.000000)]\n",
      "[Value(data=-0.931098, grad=0.000000)]\n",
      "[Value(data=-0.931098, grad=0.000000)]\n",
      "[Value(data=-0.931098, grad=0.000000)]\n",
      "[Value(data=-0.931098, grad=0.000000)]\n",
      "step 47 loss 1.1520882511996717, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.930991, grad=0.000000)]\n",
      "[Value(data=-0.930991, grad=0.000000)]\n",
      "[Value(data=-0.930991, grad=0.000000)]\n",
      "[Value(data=-0.930991, grad=0.000000)]\n",
      "[Value(data=-0.930991, grad=0.000000)]\n",
      "step 48 loss 1.1520531512566787, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.930885, grad=0.000000)]\n",
      "[Value(data=-0.930885, grad=0.000000)]\n",
      "[Value(data=-0.930885, grad=0.000000)]\n",
      "[Value(data=-0.930885, grad=0.000000)]\n",
      "[Value(data=-0.930885, grad=0.000000)]\n",
      "step 49 loss 1.152018606742953, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.930781, grad=0.000000)]\n",
      "[Value(data=-0.930781, grad=0.000000)]\n",
      "[Value(data=-0.930781, grad=0.000000)]\n",
      "[Value(data=-0.930781, grad=0.000000)]\n",
      "[Value(data=-0.930781, grad=0.000000)]\n",
      "step 50 loss 1.1519846172826025, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.930679, grad=0.000000)]\n",
      "[Value(data=-0.930679, grad=0.000000)]\n",
      "[Value(data=-0.930679, grad=0.000000)]\n",
      "[Value(data=-0.930679, grad=0.000000)]\n",
      "[Value(data=-0.930679, grad=0.000000)]\n",
      "step 51 loss 1.1519511825058144, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.930578, grad=0.000000)]\n",
      "[Value(data=-0.930578, grad=0.000000)]\n",
      "[Value(data=-0.930578, grad=0.000000)]\n",
      "[Value(data=-0.930578, grad=0.000000)]\n",
      "[Value(data=-0.930578, grad=0.000000)]\n",
      "step 52 loss 1.1519183020488486, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.930479, grad=0.000000)]\n",
      "[Value(data=-0.930479, grad=0.000000)]\n",
      "[Value(data=-0.930479, grad=0.000000)]\n",
      "[Value(data=-0.930479, grad=0.000000)]\n",
      "[Value(data=-0.930479, grad=0.000000)]\n",
      "step 53 loss 1.151885975554034, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.930381, grad=0.000000)]\n",
      "[Value(data=-0.930381, grad=0.000000)]\n",
      "[Value(data=-0.930381, grad=0.000000)]\n",
      "[Value(data=-0.930381, grad=0.000000)]\n",
      "[Value(data=-0.930381, grad=0.000000)]\n",
      "step 54 loss 1.151854202669757, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.930286, grad=0.000000)]\n",
      "[Value(data=-0.930286, grad=0.000000)]\n",
      "[Value(data=-0.930286, grad=0.000000)]\n",
      "[Value(data=-0.930286, grad=0.000000)]\n",
      "[Value(data=-0.930286, grad=0.000000)]\n",
      "step 55 loss 1.1518229830504585, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.930192, grad=0.000000)]\n",
      "[Value(data=-0.930192, grad=0.000000)]\n",
      "[Value(data=-0.930192, grad=0.000000)]\n",
      "[Value(data=-0.930192, grad=0.000000)]\n",
      "[Value(data=-0.930192, grad=0.000000)]\n",
      "step 56 loss 1.1517923163566286, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.930100, grad=0.000000)]\n",
      "[Value(data=-0.930100, grad=0.000000)]\n",
      "[Value(data=-0.930100, grad=0.000000)]\n",
      "[Value(data=-0.930100, grad=0.000000)]\n",
      "[Value(data=-0.930100, grad=0.000000)]\n",
      "step 57 loss 1.1517622022547973, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.930009, grad=0.000000)]\n",
      "[Value(data=-0.930009, grad=0.000000)]\n",
      "[Value(data=-0.930009, grad=0.000000)]\n",
      "[Value(data=-0.930009, grad=0.000000)]\n",
      "[Value(data=-0.930009, grad=0.000000)]\n",
      "step 58 loss 1.1517326404175294, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929920, grad=0.000000)]\n",
      "[Value(data=-0.929920, grad=0.000000)]\n",
      "[Value(data=-0.929920, grad=0.000000)]\n",
      "[Value(data=-0.929920, grad=0.000000)]\n",
      "[Value(data=-0.929920, grad=0.000000)]\n",
      "step 59 loss 1.151703630523421, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929833, grad=0.000000)]\n",
      "[Value(data=-0.929833, grad=0.000000)]\n",
      "[Value(data=-0.929833, grad=0.000000)]\n",
      "[Value(data=-0.929833, grad=0.000000)]\n",
      "[Value(data=-0.929833, grad=0.000000)]\n",
      "step 60 loss 1.1516751722570897, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929747, grad=0.000000)]\n",
      "[Value(data=-0.929747, grad=0.000000)]\n",
      "[Value(data=-0.929747, grad=0.000000)]\n",
      "[Value(data=-0.929747, grad=0.000000)]\n",
      "[Value(data=-0.929747, grad=0.000000)]\n",
      "step 61 loss 1.1516472653091738, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929663, grad=0.000000)]\n",
      "[Value(data=-0.929663, grad=0.000000)]\n",
      "[Value(data=-0.929663, grad=0.000000)]\n",
      "[Value(data=-0.929663, grad=0.000000)]\n",
      "[Value(data=-0.929663, grad=0.000000)]\n",
      "step 62 loss 1.1516199093763202, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929581, grad=0.000000)]\n",
      "[Value(data=-0.929581, grad=0.000000)]\n",
      "[Value(data=-0.929581, grad=0.000000)]\n",
      "[Value(data=-0.929581, grad=0.000000)]\n",
      "[Value(data=-0.929581, grad=0.000000)]\n",
      "step 63 loss 1.1515931041611849, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929501, grad=0.000000)]\n",
      "[Value(data=-0.929501, grad=0.000000)]\n",
      "[Value(data=-0.929501, grad=0.000000)]\n",
      "[Value(data=-0.929501, grad=0.000000)]\n",
      "[Value(data=-0.929501, grad=0.000000)]\n",
      "step 64 loss 1.1515668493724258, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929422, grad=0.000000)]\n",
      "[Value(data=-0.929422, grad=0.000000)]\n",
      "[Value(data=-0.929422, grad=0.000000)]\n",
      "[Value(data=-0.929422, grad=0.000000)]\n",
      "[Value(data=-0.929422, grad=0.000000)]\n",
      "step 65 loss 1.1515411447246955, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929345, grad=0.000000)]\n",
      "[Value(data=-0.929345, grad=0.000000)]\n",
      "[Value(data=-0.929345, grad=0.000000)]\n",
      "[Value(data=-0.929345, grad=0.000000)]\n",
      "[Value(data=-0.929345, grad=0.000000)]\n",
      "step 66 loss 1.151515989938638, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929269, grad=0.000000)]\n",
      "[Value(data=-0.929269, grad=0.000000)]\n",
      "[Value(data=-0.929269, grad=0.000000)]\n",
      "[Value(data=-0.929269, grad=0.000000)]\n",
      "[Value(data=-0.929269, grad=0.000000)]\n",
      "step 67 loss 1.1514913847408836, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929196, grad=0.000000)]\n",
      "[Value(data=-0.929196, grad=0.000000)]\n",
      "[Value(data=-0.929196, grad=0.000000)]\n",
      "[Value(data=-0.929196, grad=0.000000)]\n",
      "[Value(data=-0.929196, grad=0.000000)]\n",
      "step 68 loss 1.1514673288640431, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929123, grad=0.000000)]\n",
      "[Value(data=-0.929123, grad=0.000000)]\n",
      "[Value(data=-0.929123, grad=0.000000)]\n",
      "[Value(data=-0.929123, grad=0.000000)]\n",
      "[Value(data=-0.929123, grad=0.000000)]\n",
      "step 69 loss 1.1514438220467034, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.929053, grad=0.000000)]\n",
      "[Value(data=-0.929053, grad=0.000000)]\n",
      "[Value(data=-0.929053, grad=0.000000)]\n",
      "[Value(data=-0.929053, grad=0.000000)]\n",
      "[Value(data=-0.929053, grad=0.000000)]\n",
      "step 70 loss 1.151420864033423, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928984, grad=0.000000)]\n",
      "[Value(data=-0.928984, grad=0.000000)]\n",
      "[Value(data=-0.928984, grad=0.000000)]\n",
      "[Value(data=-0.928984, grad=0.000000)]\n",
      "[Value(data=-0.928984, grad=0.000000)]\n",
      "step 71 loss 1.1513984545747264, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928917, grad=0.000000)]\n",
      "[Value(data=-0.928917, grad=0.000000)]\n",
      "[Value(data=-0.928917, grad=0.000000)]\n",
      "[Value(data=-0.928917, grad=0.000000)]\n",
      "[Value(data=-0.928917, grad=0.000000)]\n",
      "step 72 loss 1.1513765934271016, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928852, grad=0.000000)]\n",
      "[Value(data=-0.928852, grad=0.000000)]\n",
      "[Value(data=-0.928852, grad=0.000000)]\n",
      "[Value(data=-0.928852, grad=0.000000)]\n",
      "[Value(data=-0.928852, grad=0.000000)]\n",
      "step 73 loss 1.1513552803529936, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928788, grad=0.000000)]\n",
      "[Value(data=-0.928788, grad=0.000000)]\n",
      "[Value(data=-0.928788, grad=0.000000)]\n",
      "[Value(data=-0.928788, grad=0.000000)]\n",
      "[Value(data=-0.928788, grad=0.000000)]\n",
      "step 74 loss 1.1513345151208012, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928726, grad=0.000000)]\n",
      "[Value(data=-0.928726, grad=0.000000)]\n",
      "[Value(data=-0.928726, grad=0.000000)]\n",
      "[Value(data=-0.928726, grad=0.000000)]\n",
      "[Value(data=-0.928726, grad=0.000000)]\n",
      "step 75 loss 1.151314297504872, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928666, grad=0.000000)]\n",
      "[Value(data=-0.928666, grad=0.000000)]\n",
      "[Value(data=-0.928666, grad=0.000000)]\n",
      "[Value(data=-0.928666, grad=0.000000)]\n",
      "[Value(data=-0.928666, grad=0.000000)]\n",
      "step 76 loss 1.1512946272854994, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928607, grad=0.000000)]\n",
      "[Value(data=-0.928607, grad=0.000000)]\n",
      "[Value(data=-0.928607, grad=0.000000)]\n",
      "[Value(data=-0.928607, grad=0.000000)]\n",
      "[Value(data=-0.928607, grad=0.000000)]\n",
      "step 77 loss 1.1512755042489176, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928550, grad=0.000000)]\n",
      "[Value(data=-0.928550, grad=0.000000)]\n",
      "[Value(data=-0.928550, grad=0.000000)]\n",
      "[Value(data=-0.928550, grad=0.000000)]\n",
      "[Value(data=-0.928550, grad=0.000000)]\n",
      "step 78 loss 1.1512569281872984, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928495, grad=0.000000)]\n",
      "[Value(data=-0.928495, grad=0.000000)]\n",
      "[Value(data=-0.928495, grad=0.000000)]\n",
      "[Value(data=-0.928495, grad=0.000000)]\n",
      "[Value(data=-0.928495, grad=0.000000)]\n",
      "step 79 loss 1.1512388988987472, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928441, grad=0.000000)]\n",
      "[Value(data=-0.928441, grad=0.000000)]\n",
      "[Value(data=-0.928441, grad=0.000000)]\n",
      "[Value(data=-0.928441, grad=0.000000)]\n",
      "[Value(data=-0.928441, grad=0.000000)]\n",
      "step 80 loss 1.1512214161872996, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928389, grad=0.000000)]\n",
      "[Value(data=-0.928389, grad=0.000000)]\n",
      "[Value(data=-0.928389, grad=0.000000)]\n",
      "[Value(data=-0.928389, grad=0.000000)]\n",
      "[Value(data=-0.928389, grad=0.000000)]\n",
      "step 81 loss 1.1512044798629169, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928339, grad=0.000000)]\n",
      "[Value(data=-0.928339, grad=0.000000)]\n",
      "[Value(data=-0.928339, grad=0.000000)]\n",
      "[Value(data=-0.928339, grad=0.000000)]\n",
      "[Value(data=-0.928339, grad=0.000000)]\n",
      "step 82 loss 1.1511880897414843, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928290, grad=0.000000)]\n",
      "[Value(data=-0.928290, grad=0.000000)]\n",
      "[Value(data=-0.928290, grad=0.000000)]\n",
      "[Value(data=-0.928290, grad=0.000000)]\n",
      "[Value(data=-0.928290, grad=0.000000)]\n",
      "step 83 loss 1.151172245644805, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928243, grad=0.000000)]\n",
      "[Value(data=-0.928243, grad=0.000000)]\n",
      "[Value(data=-0.928243, grad=0.000000)]\n",
      "[Value(data=-0.928243, grad=0.000000)]\n",
      "[Value(data=-0.928243, grad=0.000000)]\n",
      "step 84 loss 1.1511569474006011, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928198, grad=0.000000)]\n",
      "[Value(data=-0.928198, grad=0.000000)]\n",
      "[Value(data=-0.928198, grad=0.000000)]\n",
      "[Value(data=-0.928198, grad=0.000000)]\n",
      "[Value(data=-0.928198, grad=0.000000)]\n",
      "step 85 loss 1.1511421948425067, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928154, grad=0.000000)]\n",
      "[Value(data=-0.928154, grad=0.000000)]\n",
      "[Value(data=-0.928154, grad=0.000000)]\n",
      "[Value(data=-0.928154, grad=0.000000)]\n",
      "[Value(data=-0.928154, grad=0.000000)]\n",
      "step 86 loss 1.1511279878100642, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928112, grad=0.000000)]\n",
      "[Value(data=-0.928112, grad=0.000000)]\n",
      "[Value(data=-0.928112, grad=0.000000)]\n",
      "[Value(data=-0.928112, grad=0.000000)]\n",
      "[Value(data=-0.928112, grad=0.000000)]\n",
      "step 87 loss 1.1511143261487269, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928072, grad=0.000000)]\n",
      "[Value(data=-0.928072, grad=0.000000)]\n",
      "[Value(data=-0.928072, grad=0.000000)]\n",
      "[Value(data=-0.928072, grad=0.000000)]\n",
      "[Value(data=-0.928072, grad=0.000000)]\n",
      "step 88 loss 1.15110120970985, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.928033, grad=0.000000)]\n",
      "[Value(data=-0.928033, grad=0.000000)]\n",
      "[Value(data=-0.928033, grad=0.000000)]\n",
      "[Value(data=-0.928033, grad=0.000000)]\n",
      "[Value(data=-0.928033, grad=0.000000)]\n",
      "step 89 loss 1.1510886383506918, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.927996, grad=0.000000)]\n",
      "[Value(data=-0.927996, grad=0.000000)]\n",
      "[Value(data=-0.927996, grad=0.000000)]\n",
      "[Value(data=-0.927996, grad=0.000000)]\n",
      "[Value(data=-0.927996, grad=0.000000)]\n",
      "step 90 loss 1.15107661193441, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.927961, grad=0.000000)]\n",
      "[Value(data=-0.927961, grad=0.000000)]\n",
      "[Value(data=-0.927961, grad=0.000000)]\n",
      "[Value(data=-0.927961, grad=0.000000)]\n",
      "[Value(data=-0.927961, grad=0.000000)]\n",
      "step 91 loss 1.1510651303300574, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.927927, grad=0.000000)]\n",
      "[Value(data=-0.927927, grad=0.000000)]\n",
      "[Value(data=-0.927927, grad=0.000000)]\n",
      "[Value(data=-0.927927, grad=0.000000)]\n",
      "[Value(data=-0.927927, grad=0.000000)]\n",
      "step 92 loss 1.1510541934125829, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.927896, grad=0.000000)]\n",
      "[Value(data=-0.927896, grad=0.000000)]\n",
      "[Value(data=-0.927896, grad=0.000000)]\n",
      "[Value(data=-0.927896, grad=0.000000)]\n",
      "[Value(data=-0.927896, grad=0.000000)]\n",
      "step 93 loss 1.1510438010628279, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.927865, grad=0.000000)]\n",
      "[Value(data=-0.927865, grad=0.000000)]\n",
      "[Value(data=-0.927865, grad=0.000000)]\n",
      "[Value(data=-0.927865, grad=0.000000)]\n",
      "[Value(data=-0.927865, grad=0.000000)]\n",
      "step 94 loss 1.151033953167522, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.927837, grad=0.000000)]\n",
      "[Value(data=-0.927837, grad=0.000000)]\n",
      "[Value(data=-0.927837, grad=0.000000)]\n",
      "[Value(data=-0.927837, grad=0.000000)]\n",
      "[Value(data=-0.927837, grad=0.000000)]\n",
      "step 95 loss 1.1510246496192833, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.927810, grad=0.000000)]\n",
      "[Value(data=-0.927810, grad=0.000000)]\n",
      "[Value(data=-0.927810, grad=0.000000)]\n",
      "[Value(data=-0.927810, grad=0.000000)]\n",
      "[Value(data=-0.927810, grad=0.000000)]\n",
      "step 96 loss 1.151015890316617, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.927785, grad=0.000000)]\n",
      "[Value(data=-0.927785, grad=0.000000)]\n",
      "[Value(data=-0.927785, grad=0.000000)]\n",
      "[Value(data=-0.927785, grad=0.000000)]\n",
      "[Value(data=-0.927785, grad=0.000000)]\n",
      "step 97 loss 1.1510076751639118, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.927761, grad=0.000000)]\n",
      "[Value(data=-0.927761, grad=0.000000)]\n",
      "[Value(data=-0.927761, grad=0.000000)]\n",
      "[Value(data=-0.927761, grad=0.000000)]\n",
      "[Value(data=-0.927761, grad=0.000000)]\n",
      "step 98 loss 1.1510000040714374, accuracy 50.0%\n",
      "Inputs:\n",
      "[Value(data=1.574133, grad=0.000000), Value(data=-0.158067, grad=0.000000)]\n",
      "[Value(data=1.867280, grad=0.000000), Value(data=-0.023587, grad=0.000000)]\n",
      "[Value(data=-1.025964, grad=0.000000), Value(data=0.459618, grad=0.000000)]\n",
      "[Value(data=1.972278, grad=0.000000), Value(data=0.487251, grad=0.000000)]\n",
      "[Value(data=0.447130, grad=0.000000), Value(data=-0.226150, grad=0.000000)]\n",
      "Scores:\n",
      "[Value(data=-0.927739, grad=0.000000)]\n",
      "[Value(data=-0.927739, grad=0.000000)]\n",
      "[Value(data=-0.927739, grad=0.000000)]\n",
      "[Value(data=-0.927739, grad=0.000000)]\n",
      "[Value(data=-0.927739, grad=0.000000)]\n",
      "step 99 loss 1.1509928769553466, accuracy 50.0%\n"
     ]
    }
   ],
   "source": [
    "# optimization\n",
    "for k in range(100):\n",
    "    # print(\"A*********************\")\n",
    "    # print(model.get_parameters())\n",
    "    \n",
    "    # forward\n",
    "    total_loss, acc = loss()\n",
    "    # print(\"B*********************\")\n",
    "    # print(model.get_parameters())\n",
    "    \n",
    "    # backward\n",
    "    model.zero_grad()\n",
    "    # print(\"C*********************\")\n",
    "    # print(model.get_parameters())\n",
    "    total_loss.backwards()\n",
    "    # print(\"D*********************\")\n",
    "    # print(model.get_parameters())\n",
    "    \n",
    "    # update (sgd)\n",
    "    learning_rate = 1.0 - 0.9*k/100\n",
    "    for p in model.get_parameters():\n",
    "        # print(p.data)\n",
    "        # print(p.grad)\n",
    "        p.data -= learning_rate * p.grad\n",
    "    # print(\"E*********************\")\n",
    "    # print(model.get_parameters())\n",
    "    \n",
    "    if k % 1 == 0:\n",
    "        print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c964b4fe-e208-4c9f-bcad-ab0a718e7916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.6670717738661749, 2.0829282261338253)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize decision boundary\n",
    "\n",
    "h = 0.25\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Xmesh = np.c_[xx.ravel(), yy.ravel()]\n",
    "inputs = [list(map(Value, xrow)) for xrow in Xmesh]\n",
    "scores = list(map(model, inputs))\n",
    "Z = np.array([s[0].data > 0 for s in scores])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0790c7-aafe-4c56-bb81-bc741e0fc70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
